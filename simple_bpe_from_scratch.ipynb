{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D8V8Sll8MHuq"
      },
      "outputs": [],
      "source": [
        "from collections import Counter, deque"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's add **Ġ** in place of white space in between the words."
      ],
      "metadata": {
        "id": "T0Kc7TGxMj0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    \"\"\"\n",
        "    Replace spaces with a special marker 'Ġ' (except at the start) and return the processed string.\n",
        "    \"\"\"\n",
        "    processed = []\n",
        "    for i, c in enumerate(text):\n",
        "        if c == ' ' and i != 0:\n",
        "            processed.append('Ġ')\n",
        "        if c != ' ':\n",
        "            processed.append(c)\n",
        "    return ''.join(processed)"
      ],
      "metadata": {
        "id": "G2paW_bWMKXr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the vocabulary"
      ],
      "metadata": {
        "id": "bF81csZaM74E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_initial_vocab(processed_text, allowed_special):\n",
        "    \"\"\"\n",
        "    Build the initial character-level vocabulary plus any allowed special tokens.\n",
        "    Returns vocab (id->token) and inverse_vocab (token->id).\n",
        "    \"\"\"\n",
        "    # Start with all byte values\n",
        "    unique_chars = [chr(i) for i in range(256)]\n",
        "    # Add any extra chars from text\n",
        "    unique_chars.extend(ch for ch in sorted(set(processed_text)) if ch not in unique_chars)\n",
        "    if 'Ġ' not in unique_chars:\n",
        "        unique_chars.append('Ġ')\n",
        "\n",
        "    vocab = {i: ch for i, ch in enumerate(unique_chars)}\n",
        "    inverse_vocab = {ch: i for i, ch in vocab.items()}\n",
        "\n",
        "    # Add special tokens\n",
        "    for tok in allowed_special:\n",
        "        if tok not in inverse_vocab:\n",
        "            nid = len(vocab)\n",
        "            vocab[nid] = tok\n",
        "            inverse_vocab[tok] = nid\n",
        "\n",
        "    return vocab, inverse_vocab"
      ],
      "metadata": {
        "id": "FB9MBHoZMckZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_pair(token_ids, pair_id, new_id):\n",
        "    \"\"\"\n",
        "    Given a list of token IDs, merge occurrences of pair_id into new_id.\n",
        "    \"\"\"\n",
        "    dq = deque(token_ids)\n",
        "    out = []\n",
        "    while dq:\n",
        "        cur = dq.popleft()\n",
        "        if dq and (cur, dq[0]) == pair_id:\n",
        "            out.append(new_id)\n",
        "            dq.popleft()\n",
        "        else:\n",
        "            out.append(cur)\n",
        "    return out"
      ],
      "metadata": {
        "id": "87eSetB6NzHe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How `replace_pair()` Works: A Short Example\n",
        "\n",
        "Below is a step‑by‑step illustration of how `replace_pair()` takes a sequence of token IDs, looks for a specific adjacent pair, and merges every occurrence into a single new ID.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. The Inputs\n",
        "\n",
        "- **Token ID sequence**:  \n",
        "[98, 97, 110, 97, 110, 97] 'b' 'a' 'n' 'a' 'n' 'a'\n",
        "\n",
        "\n",
        "\n",
        "- **Pair to merge**:  \n",
        "`(97, 110)`  (that is, `'a'` + `'n'`)\n",
        "- **New token ID**:  \n",
        "`258`  (which we’ll think of as the subword `'an'`)\n",
        "\n",
        "---\n",
        "\n",
        "| Step | Remaining tokens (deque)     | Look at `cur` and next | Action                                | Output list      |\n",
        "|:----:|:-----------------------------|:-----------------------|:--------------------------------------|:-----------------|\n",
        "|  1   | `[98, 97, 110, 97, 110, 97]` | `cur = 98`             | `(98, 97) ≠ (97,110)` → emit `98`     | `[98]`           |\n",
        "|  2   | `[97, 110, 97, 110, 97]`     | `cur = 97`, next = 110 | matches `(97,110)` → emit `258`, skip next | `[98, 258]`  |\n",
        "|  3   | `[97, 110, 97]`              | `cur = 97`, next = 110 | matches `(97,110)` → emit `258`, skip next | `[98, 258, 258]` |\n",
        "|  4   | `[97]`                       | `cur = 97`             | no next to pair → emit `97`           | `[98, 258, 258, 97]` |\n",
        "\n",
        "---\n",
        "\n",
        "## 3. The Result\n",
        "\n",
        "```text\n",
        "[98, 258, 258, 97]\n",
        "'b', 'an', 'an', 'a'\n",
        "```\n",
        "\n",
        "**deque:** a double‑ended queue data structure that lets you append or pop items from either the front or back in O(1) time. <br> <br>\n",
        "**popleft():** a method on a deque that removes and returns the leftmost element in O(1) time.\n"
      ],
      "metadata": {
        "id": "7mZZ1663QXGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the BPE"
      ],
      "metadata": {
        "id": "VIXcQ7qmS4nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bpe(text, vocab_size, allowed_special={'<|endoftext|>'}):\n",
        "    \"\"\"\n",
        "    Train a BPE tokenizer on `text` until `vocab_size` tokens.\n",
        "    Returns:\n",
        "      - vocab: dict mapping id -> token\n",
        "      - inverse_vocab: dict mapping token -> id\n",
        "      - bpe_merges: dict mapping (p0_id, p1_id) -> new_id\n",
        "    \"\"\"\n",
        "    processed_text = preprocess(text)\n",
        "    vocab, inverse_vocab = build_initial_vocab(processed_text, allowed_special)\n",
        "    token_ids = [inverse_vocab[ch] for ch in processed_text]\n",
        "    bpe_merges = {}\n",
        "\n",
        "    for new_id in range(len(vocab), vocab_size):\n",
        "        pairs = Counter(zip(token_ids, token_ids[1:]))\n",
        "        if not pairs:\n",
        "            break\n",
        "        # Most frequent pair\n",
        "        pair_id = max(pairs.items(), key=lambda x: x[1])[0]\n",
        "        p0, p1 = pair_id\n",
        "        # Record merge\n",
        "        bpe_merges[pair_id] = new_id\n",
        "        # Add new token\n",
        "        merged = vocab[p0] + vocab[p1]\n",
        "        vocab[new_id] = merged\n",
        "        inverse_vocab[merged] = new_id\n",
        "        # Apply merge to token sequence\n",
        "        token_ids = replace_pair(token_ids, pair_id, new_id)\n",
        "\n",
        "    return vocab, inverse_vocab, bpe_merges\n"
      ],
      "metadata": {
        "id": "re4qNp7zStxa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How `train_bpe()` Works: A Short Example\n",
        "\n",
        "### 1. Inputs\n",
        "- **Text**: `banana banana`  \n",
        "- **Preprocess**: replace spaces with `Ġ` → `bananaĠbanana`  \n",
        "- **Target `vocab_size`**: initial vocab + 2 merges  \n",
        "\n",
        "### 2. Initial Vocab (IDs 0–4)\n",
        "| ID | Token           |\n",
        "|----|-----------------|\n",
        "| 0  | `b`             |\n",
        "| 1  | `a`             |\n",
        "| 2  | `n`             |\n",
        "| 3  | `Ġ`             |\n",
        "| 4  | `<\\|endoftext\\|>`   |\n",
        "\n",
        "<br> <br>\n",
        "\n",
        "Initial token IDs:  \n",
        "[0, 1, 2, 1, 2, 1, 3, 0, 1, 2, 1, 2, 1]\n",
        "\n",
        "\n",
        "### 3. Merge Iterations\n",
        "\n",
        "| Step | Most freq pair | New ID | New token | Token IDs after merge      |\n",
        "|:----:|:--------------:|:------:|:---------:|:---------------------------|\n",
        "| 1    | (1, 2)         | 5      | `an`      | [0, 5, 5, 1, 3, 0, 5, 5, 1] |\n",
        "| 2    | (0, 5)         | 6      | `ban`     | [6, 5, 1, 3, 6, 5, 1]       |\n",
        "\n",
        "### 4. Result\n",
        "- **Final vocab (size 7):**  \n",
        "  `{0:'b', 1:'a', 2:'n', 3:'Ġ', 4:'<|endoftext|>', 5:'an', 6:'ban'}`\n",
        "- **Recorded merges:**  \n",
        "  `(1,2) → 5`  \n",
        "  `(0,5) → 6`\n"
      ],
      "metadata": {
        "id": "5qp3UMgpP7kw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to show merges in an understandable format"
      ],
      "metadata": {
        "id": "8dqEIrejRQD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_merge_trees(vocab, bpe_merges):\n",
        "    \"\"\"\n",
        "    Print ASCII trees showing how each merged token is composed.\n",
        "    \"\"\"\n",
        "    # Reverse map: new_id -> (p0, p1)\n",
        "    rev = {new_id: pair for pair, new_id in bpe_merges.items()}\n",
        "\n",
        "    def recurse(tid, prefix='', is_last=True):\n",
        "        token = vocab[tid]\n",
        "        connector = '└─ ' if is_last else '├─ '\n",
        "        print(prefix + connector + repr(token))\n",
        "        if tid in rev:\n",
        "            p0, p1 = rev[tid]\n",
        "            new_prefix = prefix + ('   ' if is_last else '│  ')\n",
        "            recurse(p0, new_prefix, is_last=False)\n",
        "            recurse(p1, new_prefix, is_last=True)\n",
        "\n",
        "    print('\\nBPE Merge Trees:')\n",
        "    for (p0, p1), mid in sorted(bpe_merges.items(), key=lambda x: x[1]):\n",
        "        print(f\"\\nMerge ID {mid}: ({vocab[p0]!r}, {vocab[p1]!r}) → {mid!r} '{vocab[mid]}'\")\n",
        "        recurse(mid, prefix='', is_last=True)"
      ],
      "metadata": {
        "id": "uar90f2JUCaa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding and Decoding"
      ],
      "metadata": {
        "id": "wDerpvDARZrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text, inverse_vocab, bpe_merges):\n",
        "    \"\"\"\n",
        "    Encode `text` to a list of token IDs using the trained BPE merges.\n",
        "    \"\"\"\n",
        "    processed_text = preprocess(text)\n",
        "    token_ids = [inverse_vocab[ch] for ch in processed_text]\n",
        "    # Apply merges in order of creation\n",
        "    for pair, new_id in sorted(bpe_merges.items(), key=lambda x: x[1]):\n",
        "        token_ids = replace_pair(token_ids, pair, new_id)\n",
        "    return token_ids"
      ],
      "metadata": {
        "id": "2yT_DPY3UKZa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(token_ids, vocab):\n",
        "    \"\"\"\n",
        "    Decode a list of token IDs back to a string.\n",
        "    \"\"\"\n",
        "    text = ''.join(vocab[t] for t in token_ids)\n",
        "    # Restore spaces\n",
        "    return text.replace('Ġ', ' ')"
      ],
      "metadata": {
        "id": "mZ0RjWPlb74k"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result"
      ],
      "metadata": {
        "id": "0msihho5RcOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = 'banana banana'\n",
        "vocab_size = 500  # for demonstration\n",
        "vocab, inv_vocab, merges = train_bpe(sample, vocab_size)\n",
        "print('Vocabulary size:', len(vocab))\n",
        "display_merge_trees(vocab, merges)"
      ],
      "metadata": {
        "id": "QBPn3s4-d0Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a316489e-6225-412b-f00f-4332cc53a273"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 264\n",
            "\n",
            "BPE Merge Trees:\n",
            "\n",
            "Merge ID 258: ('a', 'n') → 258 'an'\n",
            "└─ 'an'\n",
            "   ├─ 'a'\n",
            "   └─ 'n'\n",
            "\n",
            "Merge ID 259: ('b', 'an') → 259 'ban'\n",
            "└─ 'ban'\n",
            "   ├─ 'b'\n",
            "   └─ 'an'\n",
            "      ├─ 'a'\n",
            "      └─ 'n'\n",
            "\n",
            "Merge ID 260: ('ban', 'an') → 260 'banan'\n",
            "└─ 'banan'\n",
            "   ├─ 'ban'\n",
            "   │  ├─ 'b'\n",
            "   │  └─ 'an'\n",
            "   │     ├─ 'a'\n",
            "   │     └─ 'n'\n",
            "   └─ 'an'\n",
            "      ├─ 'a'\n",
            "      └─ 'n'\n",
            "\n",
            "Merge ID 261: ('banan', 'a') → 261 'banana'\n",
            "└─ 'banana'\n",
            "   ├─ 'banan'\n",
            "   │  ├─ 'ban'\n",
            "   │  │  ├─ 'b'\n",
            "   │  │  └─ 'an'\n",
            "   │  │     ├─ 'a'\n",
            "   │  │     └─ 'n'\n",
            "   │  └─ 'an'\n",
            "   │     ├─ 'a'\n",
            "   │     └─ 'n'\n",
            "   └─ 'a'\n",
            "\n",
            "Merge ID 262: ('banana', 'Ġ') → 262 'bananaĠ'\n",
            "└─ 'bananaĠ'\n",
            "   ├─ 'banana'\n",
            "   │  ├─ 'banan'\n",
            "   │  │  ├─ 'ban'\n",
            "   │  │  │  ├─ 'b'\n",
            "   │  │  │  └─ 'an'\n",
            "   │  │  │     ├─ 'a'\n",
            "   │  │  │     └─ 'n'\n",
            "   │  │  └─ 'an'\n",
            "   │  │     ├─ 'a'\n",
            "   │  │     └─ 'n'\n",
            "   │  └─ 'a'\n",
            "   └─ 'Ġ'\n",
            "\n",
            "Merge ID 263: ('bananaĠ', 'banana') → 263 'bananaĠbanana'\n",
            "└─ 'bananaĠbanana'\n",
            "   ├─ 'bananaĠ'\n",
            "   │  ├─ 'banana'\n",
            "   │  │  ├─ 'banan'\n",
            "   │  │  │  ├─ 'ban'\n",
            "   │  │  │  │  ├─ 'b'\n",
            "   │  │  │  │  └─ 'an'\n",
            "   │  │  │  │     ├─ 'a'\n",
            "   │  │  │  │     └─ 'n'\n",
            "   │  │  │  └─ 'an'\n",
            "   │  │  │     ├─ 'a'\n",
            "   │  │  │     └─ 'n'\n",
            "   │  │  └─ 'a'\n",
            "   │  └─ 'Ġ'\n",
            "   └─ 'banana'\n",
            "      ├─ 'banan'\n",
            "      │  ├─ 'ban'\n",
            "      │  │  ├─ 'b'\n",
            "      │  │  └─ 'an'\n",
            "      │  │     ├─ 'a'\n",
            "      │  │     └─ 'n'\n",
            "      │  └─ 'an'\n",
            "      │     ├─ 'a'\n",
            "      │     └─ 'n'\n",
            "      └─ 'a'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Merges"
      ],
      "metadata": {
        "id": "vsBcb1CONFif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HSqbkT6NaLY",
        "outputId": "7847956f-1c03-4587-912d-8eee7e9fa29d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(97, 110): 258,\n",
              " (98, 258): 259,\n",
              " (259, 258): 260,\n",
              " (260, 97): 261,\n",
              " (261, 256): 262,\n",
              " (262, 261): 263}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (p0, p1), mid in merges.items():\n",
        "    left  = decode([p0], vocab)\n",
        "    right = decode([p1], vocab)\n",
        "    merged = decode([mid], vocab)\n",
        "    print(f\"({left!r}, {right!r}) -> {merged!r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV7THbdONFTm",
        "outputId": "cc1c2de5-04ac-4944-95f8-da3e77876047"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('a', 'n') -> 'an'\n",
            "('b', 'an') -> 'ban'\n",
            "('ban', 'an') -> 'banan'\n",
            "('banan', 'a') -> 'banana'\n",
            "('banana', ' ') -> 'banana '\n",
            "('banana ', 'banana') -> 'banana banana'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding and Decoding Results"
      ],
      "metadata": {
        "id": "xR8FMXreKY9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encode(\"banana\", inv_vocab, merges)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koYxYqhMJKsO",
        "outputId": "f61e063c-7155-45ab-f2dd-81a793b555da"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[261]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([261], vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l9mn0EAoKSPw",
        "outputId": "ace0f519-2c11-4b96-c89e-3c3eadb89d0e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'banana'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple working of BPE is demonstrated."
      ],
      "metadata": {
        "id": "CLChV3fMRnfv"
      }
    }
  ]
}